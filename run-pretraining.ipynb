{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT tanítása ONNX Runtime környezetben\n",
    "A notebook végigvezet a futtatás és tanítás lépésein AzureML környezetben. Ajánlatott az alábbi, általunk készített angol nyelvű [cikk](https://towardsdatascience.com/train-bert-large-in-your-own-language-7685ee26b05b) használata a futtatás során, azon felül, hogy lehetőségek szerint megpróbáljuk a lehető legbővebben és legértelmezhetőbben leírni a futtatás és tanítás menetét. A notebook futtatásához egy AzureML compute instance szükséges, mi ehhez a STANDARD_DS1_V2 virtuális gépet ajánljuk.\n",
    "\n",
    "Lépések:\n",
    "- AzureML Workspace betöltése\n",
    "- BLOB tároló regisztrálása\n",
    "- AzureML experiment készítése\n",
    "- Compute target (virtuális gép) készítése\n",
    "- Estimator készítése a futtatáshoz\n",
    "- Konfiguráció és futtatás\n",
    "\n",
    "Hasznos linkek:\n",
    "[Compute Instance](https://docs.microsoft.com/en-us/azure/machine-learning/concept-compute-instance)\n",
    "[Estimator használata AzureML-ben](https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/training-with-deep-learning/how-to-use-estimator/how-to-use-estimator.ipynb)\n",
    "[ONNX Runtime BERT](https://github.com/microsoft/onnxruntime-training-examples/blob/master/nvidia-bert/README.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AzureML SDK betöltése"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import sys\n",
    "\n",
    "# AzureML könyvtárak importálása\n",
    "import azureml.core\n",
    "from azureml.core import Experiment, Workspace, Datastore, Run\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.container_registry import ContainerRegistry\n",
    "from azureml.core.runconfig import MpiConfiguration, RunConfiguration, DEFAULT_GPU_IMAGE\n",
    "from azureml.train.dnn import PyTorch\n",
    "from azureml.train.estimator import Estimator\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "# AzureML SDK verzió\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AzureML Workspace beállítása"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AzureML workspace beállítása\n",
    "# info: https://docs.microsoft.com/en-us/python/api/overview/azure/ml/?view=azure-ml-py\n",
    "# illetve, https://towardsdatascience.com/train-bert-large-in-your-own-language-7685ee26b05b\n",
    "ws = Workspace.get(name=\"myworkspace\", subscription_id='<azure-subscription-id>', resource_group='myresourcegroup')\n",
    "\n",
    "# Workspace attribútumok kiíratása\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Workspace region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLOB tároló regisztrálása\n",
    "Az adathalmaz előkészítésekor BLOB tárolóba mozgattuk a kész bináris fájlokat, itt szükséges regisztálni a BLOB tárolót, amivel később hozzá tudunk férni a feltöltött fájlokhoz. Itt javasoljuk az Azure Storage Explorer használatát (https://azure.microsoft.com/en-us/features/storage-explorer/), illetve https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-access-data ezen oldal átnézését."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regisztráljuk adattárolóként a BLOB adathalmazt.\n",
    "ds = Datastore.register_azure_blob_container(workspace=ws, \n",
    "                                             datastore_name='<datastore-name>',\n",
    "                                             account_name='<storage-account-name>', \n",
    "                                             account_key='<storage-account-key>',\n",
    "                                             container_name='<storage-container-name>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datastore attribútumok kiíratása\n",
    "print('Datastore name: ' + ds.name, \n",
    "      'Container name: ' + ds.container_name, \n",
    "      'Datastore type: ' + ds.datastore_type, \n",
    "      'Workspace name: ' + ds.workspace.name, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AzureML Compute Cluster készítése\n",
    "Ezzel a pár sor kóddal AzureML Compute Cluster-t tudunk létrehozni, amin a tanítást futtatni tudjuk. Itt érdemes a kvótáknak megfelelő eszközöket használni, mi a futtatásra Standard_NC24rs_v3 vagy Standard_ND40rs_v2 gépet ajánljuk. Egy Standard_NC24rs_v3 klaszteren (virtuális gép) a futtatás körülbelül 200 órát vesz igénybe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU klaszter készítése\n",
    "gpu_cluster_name = \"ortbertpretrain\" \n",
    "try:\n",
    "    gpu_compute_target = ComputeTarget(workspace=ws, name=gpu_cluster_name)\n",
    "    print('GPU klaszter már létezik.')\n",
    "except ComputeTargetException:\n",
    "    print('Új GPU klaszter készítése...')\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='Standard_ND24rs_v3', min_nodes=0, max_nodes=8)\n",
    "    gpu_compute_target = ComputeTarget.create(ws, gpu_cluster_name, compute_config)\n",
    "    gpu_compute_target.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment készítése a futtatáshoz:\n",
    "# AzureML-ben a nagyméretű futtatások experimentként vannak jegyezve, így az AzureML SDK-val könnyedén létre tudunk hozni egy új \"kísérletet\", amivel futtatni tudjuk a tanításunkat.\n",
    "experiment_name = 'nvbert-ort-pretraining-phase1'\n",
    "experiment = Experiment(ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimator készítése\n",
    "Az AzureML Estimator az az eszköz, amivel el tudunk indítani egy új kísérletet. Itt tudjuk beállítani a hyperparamétereket is a futtatandó tanításhoz. Az alábbi táblázat segítséget nyújt a batch méret beállításához:\n",
    "\n",
    "| VM SKU             | node_count         | gpu_memory_limit_gb         | train_batch_size | gradient_accumulation_steps |\n",
    "| ------------------ |:------------------:|-----------------:|-----------------:| ---------------------------:|\n",
    "| Standard_ND40rs_v2 | 1 (8 GPUs total)   | 32  | 8192  | 64  |\n",
    "| Standard_ND40rs_v2 | 2 (16 GPUs total)  | 32  | 4096  | 32  |\n",
    "| Standard_ND40rs_v2 | 4 (32 GPUs total)  | 32  | 2048  | 16  |\n",
    "| Standard_ND40rs_v2 | 8 (64 GPUs total)  | 32  | 1024  | 8   |\n",
    "| Standard_NC24rs_v3 | 1 (4 GPUs total)   | 16  | 16320 | 340 |\n",
    "| Standard_NC24rs_v3 | 2 (8 GPUs total)   | 16  | 8160  | 170 |\n",
    "| Standard_NC24rs_v3 | 4 (16 GPUs total)  | 16  | 4080  | 85  |\n",
    "| Standard_NC24rs_v3 | 8 (32 GPUs total)  | 16  | 2016  | 42  |\n",
    "| Standard_NC24rs_v3 | 16 (64 GPUs total) | 16  | 1008  | 21  |\n",
    "\n",
    "Több infó található erről az eredeti [README.md](../README.md) fájlban."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ez a változó a projekt könyvtára, ahol a tanító szkriptek találhatóak\n",
    "project_folder = '../../workspace/BERT'\n",
    "\n",
    "# előkészített Docker képfájl, ami a Microsoft ONNX Runtime mérnökei által lett elkészítve, az AzureML platform automatikusan ezt a képfájl fogja használni a számítási klaszteren, így ez tartalmazza a számunkra szükséges eszközöket, mint a Python könytárak, vagy NVIDIA csomagok, mint a CUDA vagy CUDNN.\n",
    "image_name = 'mcr.microsoft.com/azureml/onnxruntime-training:0.1-rc3.1-openmpi4.0-cuda10.2-cudnn8.0-nccl2.7-for-bert'\n",
    "\n",
    "# MPI konfiguráció\n",
    "# Node-onkénti GPU-k számát kell itt beállítani Standard_NC24rs_v3 esetén 4, Standard_ND40rs_v2 esetén 8.\n",
    "mpi = MpiConfiguration()\n",
    "mpi.process_count_per_node = 4\n",
    "\n",
    "import uuid\n",
    "output_id = uuid.uuid1().hex\n",
    "\n",
    "# Első fázis Estimator készítése\n",
    "estimator_ph1 = Estimator(source_directory=project_folder,\n",
    "\n",
    "                    # Számítási konfiguráció\n",
    "                    compute_target = gpu_compute_target,\n",
    "                    node_count=4,\n",
    "                    process_count_per_node=1,  \n",
    "                    distributed_training = mpi,\n",
    "                    use_gpu = True,\n",
    "                    \n",
    "                    # Docker képfájl betöltése\n",
    "                    use_docker = True,\n",
    "                    custom_docker_image = image_name,\n",
    "                    user_managed = True,\n",
    "                    \n",
    "                    # Tanító szkript paraméterek\n",
    "                    # A batch méret és gradient accumulation steps, illetve gpu_memory_limit_gb paraméterekhez a fenti táblázat nyújt segítséget!\n",
    "                    script_params = {\n",
    "                        \"--config_file\": \"bert_config.json\", # általunk kívánt BERT config, small vagy base vagy large, esetleg kisebb modell.\n",
    "                        '--input_dir' : ds.path('<blob-path-to-phase1-training-data>').as_mount(), # első fázis tanító adathalmaz elérés megadása.\n",
    "                        '--output_dir': ds.path(f'output/{experiment_name}/{output_id}/').as_mount(),\n",
    "                        '--bert_model' : 'bert-large-uncased',\n",
    "                        '--train_batch_size' : 2048,\n",
    "                        '--max_seq_length': 128,\n",
    "                        '--max_predictions_per_seq': 20,\n",
    "                        '--max_steps' : 7038,\n",
    "                        '--warmup_proportion' : '0.2843',\n",
    "                        '--num_steps_per_checkpoint' : 200,\n",
    "                        '--learning_rate' : '6e-3',\n",
    "                        '--seed': 42,\n",
    "                        '--fp16' : '',\n",
    "                        '--gradient_accumulation_steps' : 16,\n",
    "                        '--allreduce_post_accumulation' : '',\n",
    "                        '--allreduce_post_accumulation_fp16' : '',\n",
    "                        '--do_train' : '',\n",
    "                        '--use_ib' : '', \n",
    "                        '--gpu_memory_limit_gb' : 16\n",
    "                    },\n",
    "                    \n",
    "                    entry_script = 'run_pretraining_ort.py',\n",
    "                    inputs = [ds.path('<blob-path-to-phase1-training-data>').as_mount()]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AzureML Experiment futtatása - Első fázis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Első fázis futtatása (ha ez lefut, akkor az Experiments oldalunk tudjuk a futtatást, logokat megnézni)\n",
    "run = experiment.submit(estimator_ph1)\n",
    "RunDetails(run).show()\n",
    "print(run.get_portal_url())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment készítése a második fázishoz, ha az első lefutott:\n",
    "experiment_name = 'nvbert-ort-pretraining-phase2'\n",
    "experiment = Experiment(ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimator készítése - Második fázis\n",
    "Ha az első fázis lefutott, akkor a második fázis következik. A szükséges paraméterekhez a lenti táblázat nyújt segítséget és emelett ne felejtsük el a második fázis adathalmazát betölteni a BLOB tárolóból.\n",
    "\n",
    "| VM SKU             | node_count         | gpu_memory_limit_gb         | train_batch_size | gradient_accumulation_steps |\n",
    "| ------------------ |:------------------:|-----------------:|-----------------:| ---------------------------:|\n",
    "| Standard_ND40rs_v2 | 1 (8 GPUs total)   | 32  | 4096 | 256  |\n",
    "| Standard_ND40rs_v2 | 2 (16 GPUs total)  | 32  | 2048 | 128  |\n",
    "| Standard_ND40rs_v2 | 4 (32 GPUs total)  | 32  | 1024 | 64   |\n",
    "| Standard_ND40rs_v2 | 8 (64 GPUs total)  | 32  | 512  | 32   |\n",
    "| Standard_NC24rs_v3 | 1 (4 GPUs total)   | 16  | 8192 | 1024 |\n",
    "| Standard_NC24rs_v3 | 2 (8 GPUs total)   | 16  | 4096 | 512  |\n",
    "| Standard_NC24rs_v3 | 4 (16 GPUs total)  | 16  | 2048 | 256  |\n",
    "| Standard_NC24rs_v3 | 8 (32 GPUs total)  | 16  | 1024 | 128  |\n",
    "| Standard_NC24rs_v3 | 16 (64 GPUs total) | 16  | 512  | 64   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Estimator készítése a második fázishoz:\n",
    "estimator_ph2 = Estimator(source_directory=project_folder,\n",
    "\n",
    "                    # Számítási konfiguráció\n",
    "                    compute_target = gpu_compute_target,\n",
    "                    node_count=4, \n",
    "                    process_count_per_node=1, \n",
    "                    distributed_training = mpi,\n",
    "                    use_gpu = True,\n",
    "                    \n",
    "                    # Docker képfájl betöltése\n",
    "                    use_docker = True,\n",
    "                    custom_docker_image = image_name,\n",
    "                    user_managed = True,\n",
    "                    \n",
    "                    # Tanító szkript paraméterek\n",
    "                    script_params = {\n",
    "                        \"--config_file\": \"bert_config.json\",\n",
    "                        '--input_dir' : ds.path('<blob-path-to-phase2-training-data>').as_mount(), \n",
    "                        '--output_dir': ds.path(f'output/{experiment_name}/{output_id}/').as_mount(),\n",
    "                        '--bert_model' : 'bert-large-uncased',\n",
    "                        '--train_batch_size' : 1024,\n",
    "                        '--max_seq_length': 512,\n",
    "                        '--max_predictions_per_seq': 80,\n",
    "                        '--max_steps' : 1563,\n",
    "                        '--warmup_proportion' : '0.128',\n",
    "                        '--num_steps_per_checkpoint' : 200,\n",
    "                        '--learning_rate' : '4e-3',\n",
    "                        '--seed': 42,\n",
    "                        '--fp16' : '',\n",
    "                        '--gradient_accumulation_steps' : 64,\n",
    "                        '--allreduce_post_accumulation' : '',\n",
    "                        '--allreduce_post_accumulation_fp16' : '',\n",
    "                        '--do_train' : '',\n",
    "                        '--phase2' : '',\n",
    "                        '--resume_from_checkpoint' : '',\n",
    "                        '--phase1_end_step' : '7038',\n",
    "                        '--init_checkpoint' : ds.path('<path-to-checkpoint-from-phase-1>'),\n",
    "                        '--use_ib' : '', \n",
    "                        '--gpu_memory_limit_gb' : 16\n",
    "                    },\n",
    "                    \n",
    "                    entry_script='run_pretraining_ort.py',\n",
    "                    inputs=[ds.path('<blob-path-to-phase2-training-data>').as_mount()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AzureML Experiment futtatása - Második fázis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Második fázis futtatása (ha ez lefut, akkor az Experiments oldalunk tudjuk a futtatást, logokat megnézni)\n",
    "run = experiment.submit(estimator_ph2)\n",
    "RunDetails(run).show()\n",
    "print(run.get_portal_url())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}